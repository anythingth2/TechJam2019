{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, CuDNNGRU, Bidirectional, Dense, InputLayer, Dropout, BatchNormalization, Reshape, Flatten, Conv1D, AveragePooling1D, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import modified_SMAPE\n",
    "from losses import SMAPE_loss\n",
    "from callbacks import EvaluateSMAPE\n",
    "from tqdm import tqdm, trange, tnrange\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograpgics = pd.read_csv('datasets/exam-1/demographics.csv')\n",
    "cc = pd.read_csv('datasets/exam-1/cc.csv')\n",
    "cc.sort_values(by=['cc_no', 'pos_dt'], inplace=True)\n",
    "kplus = pd.read_csv('datasets/exam-1/kplus.csv')\n",
    "kplus.sort_values(by=['id', 'sunday'], inplace=True)\n",
    "train_set = pd.read_csv('datasets/exam-1/train.csv')\n",
    "test_set = pd.read_csv('datasets/exam-1/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_transaction_threshold = 8\n",
    "\n",
    "train_kplus = kplus.copy()\n",
    "grouped = train_kplus.groupby('id')\n",
    "trainable_ids = grouped.size().keys()[grouped.size() >= n_transaction_threshold]\n",
    "train_kplus = train_kplus[train_kplus['id'].isin(trainable_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sunday</th>\n",
       "      <th>kp_txn_count</th>\n",
       "      <th>kp_txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100625</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100629</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100641</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100643</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>4</td>\n",
       "      <td>13700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      sunday  kp_txn_count  kp_txn_amt\n",
       "100625   2  2018-01-07             2         600\n",
       "100629   2  2018-01-14             3        3200\n",
       "100641   2  2018-01-21             2         600\n",
       "100644   2  2018-01-28             6        3000\n",
       "100643   2  2018-02-04             4       13700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kplus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "scaler_x = Scaler()\n",
    "train_kplus[['kp_txn_count', 'kp_txn_amt']] = scaler_x.fit_transform(train_kplus[['kp_txn_count', 'kp_txn_amt']])\n",
    "train_kplus = train_kplus[train_kplus['id'] <= 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sunday</th>\n",
       "      <th>kp_txn_count</th>\n",
       "      <th>kp_txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100625</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>-0.404434</td>\n",
       "      <td>-0.218776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100629</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>-0.237545</td>\n",
       "      <td>-0.198626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100641</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>-0.404434</td>\n",
       "      <td>-0.218776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0.263124</td>\n",
       "      <td>-0.200176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100643</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>-0.070655</td>\n",
       "      <td>-0.117253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      sunday  kp_txn_count  kp_txn_amt\n",
       "100625   2  2018-01-07     -0.404434   -0.218776\n",
       "100629   2  2018-01-14     -0.237545   -0.198626\n",
       "100641   2  2018-01-21     -0.404434   -0.218776\n",
       "100644   2  2018-01-28      0.263124   -0.200176\n",
       "100643   2  2018-02-04     -0.070655   -0.117253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kplus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "padding_value = float(-100)\n",
    "max_len = len(kplus.groupby('sunday').groups)\n",
    "sunday_id_hash = {sunday:i for i, sunday in enumerate(kplus.groupby('sunday', sort=True).groups.keys())}\n",
    "\n",
    "id_grouped = train_kplus.groupby('id')\n",
    "accept_ids = pd.Series(list(id_grouped.groups.keys()))\n",
    "\n",
    "def create_sequence(group):\n",
    "    origin = sunday_id_hash[group.iloc[0]['sunday']]\n",
    "\n",
    "    seq = group[['kp_txn_amt', 'kp_txn_count']].to_numpy()\n",
    "    pre_padding = np.ones((origin ,2), dtype=np.float32) * padding_value\n",
    "    post_padding = np.ones((max_len - origin - len(seq),2), dtype=np.float32) * padding_value\n",
    "    return np.concatenate((pre_padding, seq, post_padding), axis=0)\n",
    "xs = np.array([create_sequence(group) for _, group in id_grouped])\n",
    "\n",
    "ys = train_set[train_set['id'].isin(accept_ids)]['income'].to_numpy()\n",
    "income_mean = train_set['income'].mean()\n",
    "income_std = train_set['income'].std()\n",
    "# ys = (ys - income_mean) / income_std\n",
    "# ys = (ys - ys.min()) / ys.max()\n",
    "scaler_y = Scaler()\n",
    "ys = np.squeeze(scaler_y.fit_transform(np.expand_dims(ys,axis=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [   0,    0],\n",
       "       [-100, -100],\n",
       "       [-100, -100],\n",
       "       [-100, -100],\n",
       "       [-100, -100],\n",
       "       [-100, -100],\n",
       "       [-100, -100]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6848973340576062"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_activation = 'tanh'\n",
    "model = Sequential()\n",
    "model.add(InputLayer((25,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LSTM(32, return_sequences=True, ))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(32, return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(GRU(50, activation=base_activation, return_sequences=True))\n",
    "model.add(GRU(50, activation=base_activation, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(25, activation=base_activation, return_sequences=True))\n",
    "model.add(GRU(25, activation=base_activation, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(100))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "base_activation = 'linear'\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation, input_shape=(25,2)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((25,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=4e-2, momentum=0.1)\n",
    "opt = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 23, 32)            224       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 21, 32)            3104      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 19, 16)            1552      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 17, 16)            784       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 8)             392       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 13, 8)             200       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 11, 4)             100       \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 9, 4)              52        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 6,445\n",
      "Trainable params: 6,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=SMAPE_loss(scaler_y), optimizer=opt )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(xs, ys, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27725 samples, validate on 6932 samples\n",
      "Epoch 1/10000\n",
      "27725/27725 [==============================] - 4s 145us/step - loss: 7.4500 - val_loss: 0.1495\n",
      "Epoch 1 | val-SMAPE: 85.04502805701172\n",
      "Epoch 2/10000\n",
      "27725/27725 [==============================] - 4s 140us/step - loss: 0.8212 - val_loss: 0.1202\n",
      "Epoch 2 | val-SMAPE: 87.984437422383\n",
      "Epoch 3/10000\n",
      "27725/27725 [==============================] - 4s 139us/step - loss: 0.3694 - val_loss: 0.1174\n",
      "Epoch 3 | val-SMAPE: 88.2607059285638\n",
      "Epoch 4/10000\n",
      "27725/27725 [==============================] - 4s 141us/step - loss: 0.2300 - val_loss: 0.1101\n",
      "Epoch 4 | val-SMAPE: 88.98974448502648\n",
      "Epoch 5/10000\n",
      "27725/27725 [==============================] - 4s 140us/step - loss: 0.2430 - val_loss: 0.1104\n",
      "Epoch 5 | val-SMAPE: 88.96326039285242\n",
      "Epoch 6/10000\n",
      "27725/27725 [==============================] - 4s 142us/step - loss: 0.2763 - val_loss: 0.1081\n",
      "Epoch 6 | val-SMAPE: 89.19485844822199\n",
      "Epoch 7/10000\n",
      "27725/27725 [==============================] - 4s 142us/step - loss: 0.2692 - val_loss: 0.1170\n",
      "Epoch 7 | val-SMAPE: 88.30363807293699\n",
      "Epoch 8/10000\n",
      "27725/27725 [==============================] - 4s 152us/step - loss: 0.1842 - val_loss: 0.1081\n",
      "Epoch 8 | val-SMAPE: 89.18695283147619\n",
      "Epoch 9/10000\n",
      "27725/27725 [==============================] - 4s 138us/step - loss: 0.1533 - val_loss: 0.1067\n",
      "Epoch 9 | val-SMAPE: 89.33297288483165\n",
      "Epoch 10/10000\n",
      "27725/27725 [==============================] - 4s 141us/step - loss: 0.1360 - val_loss: 0.1086\n",
      "Epoch 10 | val-SMAPE: 89.13977876890277\n",
      "Epoch 11/10000\n",
      "27725/27725 [==============================] - 4s 147us/step - loss: 0.1240 - val_loss: 0.1048\n",
      "Epoch 11 | val-SMAPE: 89.51805483698158\n",
      "Epoch 12/10000\n",
      "27725/27725 [==============================] - 4s 141us/step - loss: 0.1143 - val_loss: 0.1051\n",
      "Epoch 12 | val-SMAPE: 89.49005603618313\n",
      "Epoch 13/10000\n",
      "27725/27725 [==============================] - 4s 143us/step - loss: 0.1114 - val_loss: 0.1046\n",
      "Epoch 13 | val-SMAPE: 89.53882894821065\n",
      "Epoch 14/10000\n",
      "27725/27725 [==============================] - 4s 137us/step - loss: 0.1104 - val_loss: 0.1046\n",
      "Epoch 14 | val-SMAPE: 89.54107987308048\n",
      "Epoch 15/10000\n",
      "27725/27725 [==============================] - 4s 130us/step - loss: 0.1083 - val_loss: 0.1045\n",
      "Epoch 15 | val-SMAPE: 89.55072437279223\n",
      "Epoch 16/10000\n",
      "27725/27725 [==============================] - 4s 132us/step - loss: 0.1077 - val_loss: 0.1052\n",
      "Epoch 16 | val-SMAPE: 89.47588748739796\n",
      "Epoch 17/10000\n",
      "27725/27725 [==============================] - 4s 138us/step - loss: 0.1074 - val_loss: 0.1041\n",
      "Epoch 17 | val-SMAPE: 89.58644758452071\n",
      "Epoch 18/10000\n",
      " 4832/27725 [====>.........................] - ETA: 2s - loss: 0.1098"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-580d5aa8c767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      TensorBoard(log_dir='logs/cnn-smape')],\n\u001b[1;32m      7\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          epochs=10000)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True,\n",
    "          batch_size=32,\n",
    "          callbacks=[EvaluateSMAPE(x_val, y_val, 'val', scaler_y=scaler_y, use_SMAPE_loss=True),\n",
    "                     TensorBoard(log_dir='logs/cnn-smape')],\n",
    "          initial_epoch=0,\n",
    "         epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_id = pd.merge(cc, demograpgics[['id','cc_no']], on='cc_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_id['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_no</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>3800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>14700</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>30000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cc_no      pos_dt  cc_txn_amt  id  count\n",
       "0      2  2018-03-10         800   2      1\n",
       "1      2  2018-03-12        3800   2      1\n",
       "2      2  2018-04-27       14700   2      1\n",
       "3      2  2018-04-29        4000   2      1\n",
       "4      2  2018-05-07         800   2      1\n",
       "5      2  2018-05-14         800   2      1\n",
       "6      2  2018-06-04        1000   2      1\n",
       "7      2  2018-06-11        1000   2      1\n",
       "8      4  2018-05-11       20000   4      1\n",
       "9      4  2018-05-11       30000   4      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_id.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = cc_id.groupby(['id', 'pos_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_no</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>98397</td>\n",
       "      <td>4700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>196794</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>98397</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>98397</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>29220</td>\n",
       "      <td>3500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>9740</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>9740</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>9740</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      pos_dt   cc_no  cc_txn_amt  count\n",
       "0   1  2018-01-20   98397        4700      1\n",
       "1   1  2018-02-17  196794       20000      2\n",
       "2   1  2018-05-13   98397       10000      1\n",
       "3   1  2018-06-14   98397       10000      1\n",
       "4   2  2018-01-04    9740        1600      1\n",
       "5   2  2018-01-28   29220        3500      3\n",
       "6   2  2018-01-29    9740        1500      1\n",
       "7   2  2018-02-04    9740        1100      1\n",
       "8   2  2018-02-11    9740         800      1\n",
       "9   2  2018-02-19    9740         800      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_persons = grouped.sum().reset_index()\n",
    "cc_persons.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Scaler = StandardScaler\n",
    "cc_scaler = Scaler()\n",
    "train_scaler = Scaler()\n",
    "cc_persons[['cc_txn_amt', 'count']] = cc_scaler.fit_transform(cc_persons[['cc_txn_amt', 'count']])\n",
    "scaled_train_set = train_set.copy()\n",
    "scaled_train_set['income'] = train_scaler.fit_transform(np.expand_dims(scaled_train_set['income'].to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_no</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>196794</td>\n",
       "      <td>0.421319</td>\n",
       "      <td>1.115008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.152435</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.152435</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>-0.073428</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      pos_dt   cc_no  cc_txn_amt     count\n",
       "0   1  2018-01-20   98397    0.009926 -0.366991\n",
       "1   1  2018-02-17  196794    0.421319  1.115008\n",
       "2   1  2018-05-13   98397    0.152435 -0.366991\n",
       "3   1  2018-06-14   98397    0.152435 -0.366991\n",
       "4   2  2018-01-04    9740   -0.073428 -0.366991"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.090529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.356022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.245142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.562672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    income\n",
       "0   1 -0.525099\n",
       "1   2  1.090529\n",
       "2   3 -0.356022\n",
       "3   4  0.245142\n",
       "4   5 -0.562672"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_persons = cc_persons[cc_persons['id'] <= 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_timestamp = pd.Timestamp(cc['pos_dt'].min())\n",
    "max_len_seq = (pd.Timestamp(cc['pos_dt'].max()) - origin_timestamp).days + 1\n",
    "cc_persons['pos_dt_index'] = cc_persons.apply(lambda row: (pd.Timestamp(row['pos_dt']) - origin_timestamp).days, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = float(-100)\n",
    "xs = [] # [[cc_txn_amt, count], ...]\n",
    "ys = []\n",
    "train_id_set = scaled_train_set.set_index('id')\n",
    "for _id, group in cc_persons.groupby('id'):\n",
    "    seq = np.ones((max_len_seq, 2), dtype=np.float32) * padding_value\n",
    "    seq[group['pos_dt_index'].to_numpy()] = group[['cc_txn_amt', 'count']].to_numpy()\n",
    "    \n",
    "    xs.append(seq)\n",
    "    ys.append(train_id_set.loc[_id]['income'])\n",
    "xs = np.asarray(xs)\n",
    "ys = np.asarray(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-6.8050250e-02, -3.6699140e-01],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.4273417e-02,  1.1150075e+00]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-9.4938666e-02, -3.6699140e-01],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [ 1.3899055e-01, -3.6699140e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]]], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52509903,  1.09052903,  0.24514225, ..., -0.2057307 ,\n",
       "       -0.54388541, -0.65660364])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_activation = 'tanh'\n",
    "model = Sequential()\n",
    "model.add(InputLayer((max_len_seq,2)))\n",
    "model.add(Bidirectional(CuDNNGRU(128, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Bidirectional(CuDNNGRU(128, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(CuDNNGRU(64, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Bidirectional(CuDNNGRU(64, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(CuDNNGRU(32, )))\n",
    "model.add(Activation(base_activation))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "base_activation = 'relu'\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation, input_shape=(max_len_seq,2)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((max_len_seq,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=4e-2, momentum=0.1)\n",
    "opt = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 181, 256)          101376    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 181, 256)          296448    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 181, 128)          123648    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 181, 128)          74496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 64)                31104     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 627,137\n",
      "Trainable params: 627,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=SMAPE_loss(train_scaler), optimizer=opt )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(xs, ys, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 20:19:17.997876 140082931795776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1028 20:19:19.708583 140082931795776 module_wrapper.py:137] From /home/porlolicon/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W1028 20:19:19.714822 140082931795776 module_wrapper.py:137] From /home/porlolicon/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31960 samples, validate on 7990 samples\n",
      "Epoch 1/10000\n",
      "31960/31960 [==============================] - 68s 2ms/step - loss: 0.1091 - val_loss: 0.0943\n",
      "Epoch 1 | val-SMAPE: 90.57426353704828\n",
      "Epoch 2/10000\n",
      "31960/31960 [==============================] - 65s 2ms/step - loss: 0.0971 - val_loss: 0.0969\n",
      "Epoch 2 | val-SMAPE: 90.30955666196212\n",
      "Epoch 3/10000\n",
      "31960/31960 [==============================] - 66s 2ms/step - loss: 0.0961 - val_loss: 0.0934\n",
      "Epoch 3 | val-SMAPE: 90.65647471594993\n",
      "Epoch 4/10000\n",
      "31960/31960 [==============================] - 66s 2ms/step - loss: 0.0964 - val_loss: 0.1013\n",
      "Epoch 4 | val-SMAPE: 89.86831715661117\n",
      "Epoch 5/10000\n",
      "10688/31960 [=========>....................] - ETA: 39s - loss: 0.0980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0a45f8e127de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      TensorBoard(log_dir='logs/cc_gru_smape')],\n\u001b[1;32m      7\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          epochs=10000)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True,\n",
    "          batch_size=32,\n",
    "          callbacks=[EvaluateSMAPE(x_val, y_val, 'val', scaler_y=train_scaler),\n",
    "                     TensorBoard(log_dir='logs/cc_gru_smape')],\n",
    "          initial_epoch=0,\n",
    "         epochs=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
