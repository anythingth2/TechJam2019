{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, CuDNNGRU, Bidirectional, Dense, InputLayer, Dropout, BatchNormalization, Reshape, Flatten, Conv1D, AveragePooling1D, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import modified_SMAPE\n",
    "from tqdm import tqdm, trange, tnrange\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograpgics = pd.read_csv('datasets/exam-1/demographics.csv')\n",
    "cc = pd.read_csv('datasets/exam-1/cc.csv')\n",
    "cc.sort_values(by=['cc_no', 'pos_dt'], inplace=True)\n",
    "kplus = pd.read_csv('datasets/exam-1/kplus.csv')\n",
    "kplus.sort_values(by=['id', 'sunday'], inplace=True)\n",
    "train_set = pd.read_csv('datasets/exam-1/train.csv')\n",
    "test_set = pd.read_csv('datasets/exam-1/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_transaction_threshold = 8\n",
    "\n",
    "train_kplus = kplus.copy()\n",
    "grouped = train_kplus.groupby('id')\n",
    "trainable_ids = grouped.size().keys()[grouped.size() >= n_transaction_threshold]\n",
    "train_kplus = train_kplus[train_kplus['id'].isin(trainable_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sunday</th>\n",
       "      <th>kp_txn_count</th>\n",
       "      <th>kp_txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100625</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100629</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100641</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100643</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>4</td>\n",
       "      <td>13700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      sunday  kp_txn_count  kp_txn_amt\n",
       "100625   2  2018-01-07             2         600\n",
       "100629   2  2018-01-14             3        3200\n",
       "100641   2  2018-01-21             2         600\n",
       "100644   2  2018-01-28             6        3000\n",
       "100643   2  2018-02-04             4       13700"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kplus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "scaler_x = Scaler()\n",
    "train_kplus[['kp_txn_count', 'kp_txn_amt']] = scaler_x.fit_transform(train_kplus[['kp_txn_count', 'kp_txn_amt']])\n",
    "train_kplus = train_kplus[train_kplus['id'] <= 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sunday</th>\n",
       "      <th>kp_txn_count</th>\n",
       "      <th>kp_txn_amt</th>\n",
       "      <th>count_amt_pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100625</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.005816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100629</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.003707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100641</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.005816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100643</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>-0.001374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      sunday  kp_txn_count  kp_txn_amt  count_amt_pca\n",
       "100625   2  2018-01-07      0.002217    0.000036      -0.005816\n",
       "100629   2  2018-01-14      0.004435    0.000221      -0.003707\n",
       "100641   2  2018-01-21      0.002217    0.000036      -0.005816\n",
       "100644   2  2018-01-28      0.011086    0.000206       0.002396\n",
       "100643   2  2018-02-04      0.006652    0.000968      -0.001374"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kplus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "padding_value = float(-100)\n",
    "max_len = len(kplus.groupby('sunday').groups)\n",
    "sunday_id_hash = {sunday:i for i, sunday in enumerate(kplus.groupby('sunday', sort=True).groups.keys())}\n",
    "\n",
    "id_grouped = train_kplus.groupby('id')\n",
    "accept_ids = pd.Series(list(id_grouped.groups.keys()))\n",
    "\n",
    "def create_sequence(group):\n",
    "    origin = sunday_id_hash[group.iloc[0]['sunday']]\n",
    "\n",
    "    seq = group[['kp_txn_amt', 'kp_txn_count']].to_numpy()\n",
    "    pre_padding = np.ones((origin ,2), dtype=np.float32) * padding_value\n",
    "    post_padding = np.ones((max_len - origin - len(seq),2), dtype=np.float32) * padding_value\n",
    "    return np.concatenate((pre_padding, seq, post_padding), axis=0)\n",
    "xs = np.array([create_sequence(group) for _, group in id_grouped])\n",
    "\n",
    "ys = train_set[train_set['id'].isin(accept_ids)]['income'].to_numpy()\n",
    "income_mean = train_set['income'].mean()\n",
    "income_std = train_set['income'].std()\n",
    "# ys = (ys - income_mean) / income_std\n",
    "# ys = (ys - ys.min()) / ys.max()\n",
    "scaler_y = Scaler()\n",
    "ys = np.squeeze(scaler_y.fit_transform(np.expand_dims(ys,axis=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  800,     1],\n",
       "       [ 2700,     1],\n",
       "       [  600,     1],\n",
       "       [ 1000,     1],\n",
       "       [ 1000,     1],\n",
       "       [ 1100,     1],\n",
       "       [16500,     1],\n",
       "       [26800,     1],\n",
       "       [25700,     2],\n",
       "       [  600,     1],\n",
       "       [ 1600,     1],\n",
       "       [11000,     2],\n",
       "       [10800,     3],\n",
       "       [ 1000,     1],\n",
       "       [ 6700,     2],\n",
       "       [31700,     4],\n",
       "       [ 3000,     1],\n",
       "       [14900,     1],\n",
       "       [ 7000,     1],\n",
       "       [   -1,    -1],\n",
       "       [   -1,    -1],\n",
       "       [   -1,    -1],\n",
       "       [   -1,    -1],\n",
       "       [   -1,    -1],\n",
       "       [   -1,    -1]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006122448979591837"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_activation = 'tanh'\n",
    "model = Sequential()\n",
    "model.add(InputLayer((25,2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LSTM(32, return_sequences=True, ))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(32, return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(GRU(50, activation=base_activation, return_sequences=True))\n",
    "model.add(GRU(50, activation=base_activation, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(25, activation=base_activation, return_sequences=True))\n",
    "model.add(GRU(25, activation=base_activation, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(100))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "base_activation = 'linear'\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation, input_shape=(25,2)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((25,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=4e-2, momentum=0.1)\n",
    "opt = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 25, 2)             0         \n",
      "_________________________________________________________________\n",
      "gru_117 (GRU)                (None, 25, 50)            7950      \n",
      "_________________________________________________________________\n",
      "gru_118 (GRU)                (None, 25, 50)            15150     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 25, 50)            0         \n",
      "_________________________________________________________________\n",
      "gru_119 (GRU)                (None, 25, 25)            5700      \n",
      "_________________________________________________________________\n",
      "gru_120 (GRU)                (None, 25, 25)            3825      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 25, 25)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 626       \n",
      "=================================================================\n",
      "Total params: 33,251\n",
      "Trainable params: 33,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer=opt )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(xs, ys, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateSMAPE(Callback):\n",
    "    def __init__(self, xs, ys_true, name, scaler_y=None):\n",
    "        self.scaler_y = scaler_y\n",
    "        self.xs = xs\n",
    "        \n",
    "        self.ys_true = np.squeeze(scaler_y.inverse_transform(ys_true))\n",
    "        self.name = name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ys_pred = model.predict(self.xs)\n",
    "        if self.scaler_y is not None:\n",
    "            ys_pred = np.squeeze(self.scaler_y.inverse_transform(ys_pred))\n",
    "        score = modified_SMAPE(self.ys_true, ys_pred)\n",
    "        logs[f'{self.name}-SMAPE'] = score\n",
    "        print(f'Epoch {epoch+1} | {self.name}-SMAPE: {score}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27725 samples, validate on 6932 samples\n",
      "Epoch 50/10000\n",
      "27725/27725 [==============================] - 43s 2ms/step - loss: 0.4070 - val_loss: 0.4571\n",
      "Epoch 50 | val-SMAPE: 87.15221654180186\n",
      "Epoch 51/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.4047 - val_loss: 0.4472\n",
      "Epoch 51 | val-SMAPE: 89.1394895230774\n",
      "Epoch 52/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.4028 - val_loss: 0.4526\n",
      "Epoch 52 | val-SMAPE: 88.67333321926806\n",
      "Epoch 53/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.4032 - val_loss: 0.4566\n",
      "Epoch 53 | val-SMAPE: 87.59214888186834\n",
      "Epoch 54/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.4014 - val_loss: 0.4523\n",
      "Epoch 54 | val-SMAPE: 87.71205892823158\n",
      "Epoch 55/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3992 - val_loss: 0.4579\n",
      "Epoch 55 | val-SMAPE: 87.86274694079495\n",
      "Epoch 56/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3968 - val_loss: 0.4515\n",
      "Epoch 56 | val-SMAPE: 89.60860333599614\n",
      "Epoch 57/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3968 - val_loss: 0.4549\n",
      "Epoch 57 | val-SMAPE: 88.6831478820796\n",
      "Epoch 58/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3946 - val_loss: 0.4616\n",
      "Epoch 58 | val-SMAPE: 87.15423669034872\n",
      "Epoch 59/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3952 - val_loss: 0.4611\n",
      "Epoch 59 | val-SMAPE: 87.022775470554\n",
      "Epoch 60/10000\n",
      "27725/27725 [==============================] - 39s 1ms/step - loss: 0.3936 - val_loss: 0.4627\n",
      "Epoch 60 | val-SMAPE: 88.12181861954518\n",
      "Epoch 61/10000\n",
      "27725/27725 [==============================] - 461s 17ms/step - loss: 0.3916 - val_loss: 0.4654\n",
      "Epoch 61 | val-SMAPE: 86.68477577376669\n",
      "Epoch 62/10000\n",
      "27725/27725 [==============================] - 38s 1ms/step - loss: 0.3908 - val_loss: 0.4576\n",
      "Epoch 62 | val-SMAPE: 87.85860601862507\n",
      "Epoch 63/10000\n",
      " 8032/27725 [=======>......................] - ETA: 26s - loss: 0.3808"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-94f7f36ac11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      TensorBoard(log_dir='logs/gruV4')],\n\u001b[1;32m      7\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          epochs=10000)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True,\n",
    "          batch_size=32,\n",
    "          callbacks=[EvaluateSMAPE(x_val, y_val, 'val', scaler_y=scaler_y),\n",
    "                     TensorBoard(log_dir='logs/gruV4')],\n",
    "          initial_epoch=49,\n",
    "         epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weight/gruV4-SMAPE:87.7981.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_id = pd.merge(cc, demograpgics[['id','cc_no']], on='cc_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_id['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_no</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>3800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>14700</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>30000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cc_no      pos_dt  cc_txn_amt  id  count\n",
       "0      2  2018-03-10         800   2      1\n",
       "1      2  2018-03-12        3800   2      1\n",
       "2      2  2018-04-27       14700   2      1\n",
       "3      2  2018-04-29        4000   2      1\n",
       "4      2  2018-05-07         800   2      1\n",
       "5      2  2018-05-14         800   2      1\n",
       "6      2  2018-06-04        1000   2      1\n",
       "7      2  2018-06-11        1000   2      1\n",
       "8      4  2018-05-11       20000   4      1\n",
       "9      4  2018-05-11       30000   4      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_id.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = cc_id.groupby(['id', 'pos_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_no</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>98397</td>\n",
       "      <td>4700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>196794</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>98397</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>98397</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>29220</td>\n",
       "      <td>3500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>9740</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>9740</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>9740</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      pos_dt   cc_no  cc_txn_amt  count\n",
       "0   1  2018-01-20   98397        4700      1\n",
       "1   1  2018-02-17  196794       20000      2\n",
       "2   1  2018-05-13   98397       10000      1\n",
       "3   1  2018-06-14   98397       10000      1\n",
       "4   2  2018-01-04    9740        1600      1\n",
       "5   2  2018-01-28   29220        3500      3\n",
       "6   2  2018-01-29    9740        1500      1\n",
       "7   2  2018-02-04    9740        1100      1\n",
       "8   2  2018-02-11    9740         800      1\n",
       "9   2  2018-02-19    9740         800      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_persons = grouped.sum().reset_index()\n",
    "cc_persons.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/porlolicon/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Scaler = StandardScaler\n",
    "cc_scaler = Scaler()\n",
    "train_scaler = Scaler()\n",
    "cc_persons[['cc_txn_amt', 'count']] = cc_scaler.fit_transform(cc_persons[['cc_txn_amt', 'count']])\n",
    "scaled_train_set = train_set.copy()\n",
    "scaled_train_set['income'] = train_scaler.fit_transform(np.expand_dims(scaled_train_set['income'].to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos_dt</th>\n",
       "      <th>cc_no</th>\n",
       "      <th>cc_txn_amt</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>196794</td>\n",
       "      <td>0.421319</td>\n",
       "      <td>1.115008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.152435</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>98397</td>\n",
       "      <td>0.152435</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9740</td>\n",
       "      <td>-0.073428</td>\n",
       "      <td>-0.366991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      pos_dt   cc_no  cc_txn_amt     count\n",
       "0   1  2018-01-20   98397    0.009926 -0.366991\n",
       "1   1  2018-02-17  196794    0.421319  1.115008\n",
       "2   1  2018-05-13   98397    0.152435 -0.366991\n",
       "3   1  2018-06-14   98397    0.152435 -0.366991\n",
       "4   2  2018-01-04    9740   -0.073428 -0.366991"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.525099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.090529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.356022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.245142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.562672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    income\n",
       "0   1 -0.525099\n",
       "1   2  1.090529\n",
       "2   3 -0.356022\n",
       "3   4  0.245142\n",
       "4   5 -0.562672"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_persons = cc_persons[cc_persons['id'] <= 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_timestamp = pd.Timestamp(cc['pos_dt'].min())\n",
    "max_len_seq = (pd.Timestamp(cc['pos_dt'].max()) - origin_timestamp).days + 1\n",
    "cc_persons['pos_dt_index'] = cc_persons.apply(lambda row: (pd.Timestamp(row['pos_dt']) - origin_timestamp).days, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = float(-100)\n",
    "xs = [] # [[cc_txn_amt, count], ...]\n",
    "ys = []\n",
    "train_id_set = scaled_train_set.set_index('id')\n",
    "for _id, group in cc_persons.groupby('id'):\n",
    "    seq = np.ones((max_len_seq, 2), dtype=np.float32) * padding_value\n",
    "    seq[group['pos_dt_index'].to_numpy()] = group[['cc_txn_amt', 'count']].to_numpy()\n",
    "    \n",
    "    xs.append(seq)\n",
    "    ys.append(train_id_set.loc[_id]['income'])\n",
    "xs = np.asarray(xs)\n",
    "ys = np.asarray(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-6.8050250e-02, -3.6699140e-01],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.4273417e-02,  1.1150075e+00]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-9.4938666e-02, -3.6699140e-01],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]],\n",
       "\n",
       "       [[-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [ 1.3899055e-01, -3.6699140e-01],\n",
       "        ...,\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02],\n",
       "        [-1.0000000e+02, -1.0000000e+02]]], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52509903,  1.09052903,  0.24514225, ..., -0.2057307 ,\n",
       "       -0.54388541, -0.65660364])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_activation = 'tanh'\n",
    "model = Sequential()\n",
    "model.add(InputLayer((max_len_seq,2)))\n",
    "model.add(Bidirectional(CuDNNGRU(128, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Bidirectional(CuDNNGRU(128, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(CuDNNGRU(64, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Bidirectional(CuDNNGRU(64, return_sequences=True)))\n",
    "model.add(Activation(base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(CuDNNGRU(32, )))\n",
    "model.add(Activation(base_activation))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "base_activation = 'relu'\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation, input_shape=(max_len_seq,2)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(16, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(8, kernel_size=3, activation=base_activation))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "model.add(Conv1D(4, kernel_size=3, activation=base_activation))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((max_len_seq,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE_loss(scaler):\n",
    "    mean = K.constant(scaler.mean_)\n",
    "    std = K.constant(np.sqrt(scaler.var_))\n",
    "    def loss_func(y_true, y_pred):\n",
    "        y_true = (y_true * std) + mean\n",
    "        y_pred = (y_pred * std) + mean\n",
    "        return K.mean((K.abs(y_pred - y_true) ** 2) / (( K.minimum(K.abs(y_true)*2, K.abs(y_pred)) + K.abs(y_true)) ** 2)) \n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE_np(y_true, y_pred):\n",
    "    a , f = np.array(y_true) ,np.array(y_pred)\n",
    "    return 100 - (100) * np.mean(np.power(np.abs(f - a),2) / np.power(np.minimum(2 * np.abs(a),np.abs(f)) + np.abs(a),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=4e-2, momentum=0.1)\n",
    "opt = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 181, 256)          101376    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 181, 256)          296448    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 181, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 181, 128)          123648    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 181, 128)          74496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 64)                31104     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 627,137\n",
      "Trainable params: 627,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=SMAPE_loss(train_scaler), optimizer=opt )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(xs, ys, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 20:19:17.997876 140082931795776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1028 20:19:19.708583 140082931795776 module_wrapper.py:137] From /home/porlolicon/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W1028 20:19:19.714822 140082931795776 module_wrapper.py:137] From /home/porlolicon/.local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31960 samples, validate on 7990 samples\n",
      "Epoch 1/10000\n",
      "31960/31960 [==============================] - 68s 2ms/step - loss: 0.1091 - val_loss: 0.0943\n",
      "Epoch 1 | val-SMAPE: 90.57426353704828\n",
      "Epoch 2/10000\n",
      "31960/31960 [==============================] - 65s 2ms/step - loss: 0.0971 - val_loss: 0.0969\n",
      "Epoch 2 | val-SMAPE: 90.30955666196212\n",
      "Epoch 3/10000\n",
      "31960/31960 [==============================] - 66s 2ms/step - loss: 0.0961 - val_loss: 0.0934\n",
      "Epoch 3 | val-SMAPE: 90.65647471594993\n",
      "Epoch 4/10000\n",
      "31960/31960 [==============================] - 66s 2ms/step - loss: 0.0964 - val_loss: 0.1013\n",
      "Epoch 4 | val-SMAPE: 89.86831715661117\n",
      "Epoch 5/10000\n",
      "10688/31960 [=========>....................] - ETA: 39s - loss: 0.0980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0a45f8e127de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      TensorBoard(log_dir='logs/cc_gru_smape')],\n\u001b[1;32m      7\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          epochs=10000)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True,\n",
    "          batch_size=32,\n",
    "          callbacks=[EvaluateSMAPE(x_val, y_val, 'val', scaler_y=train_scaler),\n",
    "                     TensorBoard(log_dir='logs/cc_gru_smape')],\n",
    "          initial_epoch=0,\n",
    "         epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.21697"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75000., 37000., 17000., 43000., 50000., 23000., 50000., 14000.,\n",
       "       88000., 22000.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaler.inverse_transform(y_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36747, 23314, 21383, 23101, 47924, 31014, 41069, 29239, 35962,\n",
       "       22235])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(train_scaler.inverse_transform(model.predict(x_val[:10]))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomes = train_scaler.inverse_transform(y_val[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_SMAPE(incomes, incomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.45559042413171"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_SMAPE(incomes, incomes - 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.37249598212075"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_SMAPE(incomes, incomes + 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
